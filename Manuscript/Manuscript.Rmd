---
documentclass: jss
author:
  - name: Hanne Oberman
    affiliation: Utrecht University
    address: |
      | Padualaan 14
      | 3584 CH Utrecht
    email: \email{h.i.oberman@uu.nl}
    url: https://hanneoberman.github.io/
  - name: Johanna Munoz Avila
    affiliation: University Medical Center Utrecht \AND
  - name: Valentijn de Jong
    affiliation: University Medical Center Utrecht 
  - name: Gerko Vink
    affiliation: Utrecht University \AND
  - name: Thomas Debray
    affiliation: University Medical Center Utrecht 
      # | Julius Center for Health Sciences and Primary Care, 
      # | University Medical Center Utrecht, Utrecht, The Netherlands
    #affiliation2:
title:
  formatted: "Imputation of Incomplete Multilevel Data with \\pkg{mice}"
  # If you use tex in the formatted title, also supply version without
  plain:     "Imputation of Incomplete Multilevel Data with mice"
  # For running headers, if needed
  short:     "\\pkg{mice}: Multilevel"
abstract: >
  Tutorial paper on imputing incomplete multilevel data with \pkg{mice}. Including methods for ignorable and non-ignorable missingness. 
keywords:
  # at least one keyword must be supplied
  formatted: [missing data, multilevel, clustering, "\\pkg{mice}", "\\proglang{R}"]
  plain:     [missing data, multilevel, clustering, mice, R]
preamble: >
  \usepackage{amsmath}
output: rticles::jss_article
bibliography: ../References/multilevelmice.bib
---

```{r, setup, include=FALSE}
options(prompt = 'R> ', continue = '+ ')

# packages
library(tidyverse)
library(mice)
library(miceadds)
library(metamisc)
library(pan)

# functions
miceadds::source.all(path = "../R")
icc <- function(formula, data){multilevel::ICC1(aov(formula, data))}

# plot parameters
plot_col <- mice:::mdc(1:2) %>% setNames(c("observed", "missing"))
```

# Introduction

## Multilevel data

We talk of multilevel data when there is some kind of hierarchy or clustering in a dataset. In the typical case, individuals are nested within groups, but there are many different types of multilevel data. In the medical field clustering occurs at e.g., the hospitals/center level in registry data, or at the study-level in meta-analyses (IPDMA). In the social sciences and official statistics we can find clustering e.g. at the country-level, or as imposed by the sampling design. In this paper, we will refer to the grouping variable as 'cluster', and the grouped variable as '(sample) unit'. For reasons of brevity, we only discuss clustering between units, not longitudinal data (within-unit clustering).

Multilevel data requires special care when doing any sort of analysis. The cluster to which a unit belongs may influence the unit-level observations, and since clusters are made up of units, clusters depend on units as well [@hox17]. [Explain ICC here? The percentage of variance attributed to the cluster-level is expressed by the intra-class coefficient (ICC). The ICC can also be interpreted as the expected correlation between two randomly sampled units in same cluster.] These relations can and should be taken into account when developing analysis models for multilevel data. At least, such models include a separate intercept term for each cluster. But there may also be random predictor effects and/or random error terms (residual error variances), see e.g. @hox17 and @jong21. Heterogeneity refers to variability within clusters vs. variability between clusters. There are many names for models that take clustering into account. Some popular examples are 'multilevel models', 'hierarchical models', 'mixed effect models' and 'random effect models'.

## Missing data

- Why/where does missingness occur in multilevel data? I.e., not only patient-level but also cluster-level.

- How can we categorize this? Systematic vs sporadic missingness, see @resc13. Within systematic we have two flavors: unobserved constants (same value per cluster) and non-measured random variables (which may differ per unit within clusters). In figure 1, we show a dataset with units in the rows and variables in the columns, there are 5 units nested within 2 clusters, and 3 variables of interest. Variable `X1` is completely observed. Variable `X2` is systematically missing, `X3` is sporadically missing. The unobserved value for units 4 and 5 on variable `X2` may be the same or different, defining which type of systematic missingness is happening.

```{r patterns, echo=FALSE}
# missingness indicator plot (monotone vs non-monotone)
miss_ind <- tibble(
    rownr = 5:1,
    unit = rep("observed", 5),
    cluster = rep("observed", 5),
    X1 = rep("observed", 5),
    X2 = c(rep("observed", 3), rep("missing", 2)),
    X3 = c("missing", rep("observed", 3), "missing")
  ) %>% pivot_longer(cols = c(unit, cluster, X1, X2, X3))

# add text 
miss_ind$text <- ""
miss_ind[miss_ind$name == "unit", "text"] <- as.character(1:5)
miss_ind[miss_ind$name == "cluster", "text"] <- as.character(c(1,1,1,2,2))
  
# plot
miss_ind %>% 
  mutate(name = factor(name, levels = unique(name))) %>% 
ggplot(aes(
  x = name,
  y = rownr,
  color = value,
  width = 0.8, 
  height = 0.8,
  label = text
)) +
  geom_tile(fill = "white", size = 2) +
  geom_text(show.legend = FALSE) +
  scale_x_discrete(position = "top") +
  scale_y_discrete(labels = 5:1) +
  scale_color_manual(values = plot_col, name = "") +
  theme_minimal() +
  theme(
    legend.position = "bottom", 
    panel.grid.major = element_blank()) +
  labs(x = "", y = "")
# TODO: make it one plot with sporadic and systematic
# TODO: participant/response/*sample units*/records instead of obs on the y axis

```

-	What kinds of missingness are there? ADD: missingness mechanisms here. See e.g. @yuce08 and @hox15.

- Why are standard (ad hoc) missing data methods not well suited? 

- What types of multilevel methods are available? General overview of approaches, see @audi18 and @grun18. E.g., imputation of study level versus patient-level covariates, and one-stage imputation versus two-stage imputation methods.

- Additional difficulty that is addressed in this tutorial: MNAR data.


## Aim of this paper

- Provide practical guidelines with code snippets for imputation of incomplete multilevel data. 

- We focus on the workflow for conditional modeling (not JOMO) in `mice`. Refer to other packages: `mitml`, `miceadds`, `mdmb`.

- Case study options: `metamisc::impact` (real IPD on traumatic brain injuries, without `NA`s), `mice::popularity` (simulated data on school kids, with MNAR/MAR mixture). TODO: Check example data Gelman.

- Introduce case study and set scope of this tutorial: We're providing an overview of implementations. It's up-to the reader to decide which strategy suits their data. So we won't go into detail for the different methods (and equations). This paper is just a software tutorial. We'll keep it practical. -> ADD: some kind of help function that suggests a suitable predictor matrix to the user, given a certain analysis model.


# Workflows

We'll use the IMPACT data (`metamisc::impact`) and a MAR/MNAR version of the `mice::popmis` data (i.e., a variation on the Hox (2010) popularity data, where the missingness in the variables is either missing at random (MAR) or missing not at random (MNAR)). -> ask whether we can use the Heckman repo data or simulate data ourselves

Heckman options:

- leiden85

- GJRM::hiv (https://rdrr.io/github/egeminiani/GJRM/man/hiv.html)

- simulating

- IMPACT


## Case study I: IMPACT


- What does the data look like? `impact` is traumatic brain injury data with patients clustered in studies, $n_{\text{participants}} = 11022$ and $n_{\text{clusters}} = 15$, on the following 11 variables:

  - `name` Name of the study,
  - `type` Type of study (RCT: randomized controlled trial, OBS: observational cohort),
  - `age` Age of the patient,
  - `motor_score` Glasgow Coma Scale motor score,
  - `pupil` Pupillary reactivity,
  - `ct` Marshall Computerized Tomography classification,
  - `hypox` Hypoxia (0=no, 1=yes),
  - `hypots` Hypotension (0=no, 1=yes),
  - `tsah` Traumatic subarachnoid hemorrhage (0=no, 1=yes),
  - `edh` Epidural hematoma (0=no, 1=yes),
  - `mort` 6-month mortality (0=alive, 1=dead).


```{r impact, echo=FALSE}
# load data
data("impact")
# # descriptive statistics
# by(impact, impact$name, summary) 
# psych::describe(impact)[,c(2:5,8:9)]
# missingness
plot_md_pat(impact)
# TODO: rotate variable labels

# TODO: check md pattern in clusters, should differ, otherwise create new missingness
# MAYBE: think about nr of clusters: if there's too many, faceting is no option -> some distribution across the clusters instead
# TODO: e-mail Joop for DGM or look at adrew and jennifer book for data
# sim.multi from psych
```
-> Why are there no missings? According to the [vignette](https://cran.r-project.org/web/packages/metamisc/metamisc.pdf), the data is already imputed (Steyerberg et al, 2008).

- MAR miss varying by cluster. Obs data patt differ per cluster. E.g., in cluster 1 miss depends on age but not in cluster two. Split the dataframe and run `ampute()` on each cluster. -> TODO: also make MNAR missingness to heckman model. Maybe based on `ct` variable? Inclusion-selection variable. -> otherwise: use `leiden85` data on blood pressure with MNAR. Then run cox regression like the boshuizen article but with living situation as clusters. -> TODO: get analyses from https://www.gerkovink.com/mimp/Contents/Exercises/Day%203%20-%20Wednesday/Sensitivity_analysis/Sensitivity_analysis.html.

- ADD: `multilevel_ampute()` wrapper function in `mice`.

## Case Study II: Popularity

- What does the data look like? `popNCR` is a simulated dataset with pupils clustered in classes, $n_{\text{participants}} = 2000$, $n_{\text{clusters}} = 100$, on 7 variables: 

  - `pupil`	Pupil number within class,
  - `class`	Class number,
  - `extrav`	Pupil extraversion,
  - `sex`	Pupil gender,
  - `texp`	Teacher experience (years),
  - `popular`	Pupil popularity,
  - `popteach`	Teacher popularity.
  

```{r pop, echo=FALSE, message=FALSE, warning=FALSE}
# load data and merge classes into schools for this tutorial -> but this cannot work because how texp and popteach are defined...
pop <- readRDS("../Data/popNCR.RDS") %>% mutate(school = round(0.5 + as.numeric(class)/10))

# ICCs
icc_pop <- multilevel::ICC1(aov(popular ~ as.factor(class), data = pop))
icc_teach <- multilevel::ICC1(aov(popteach ~ as.factor(class), data = pop))
```
- What are the ICCs? For `popular` the ICC is `r round(icc_pop, 2)`. For `popteach` it is `r round(icc_teach, 2)`. It would be wise to use multilevel modeling.

- What does the missingness look like? Induced MAR/MNAR missingness. Missing data pattern:

```{r pop_pat, echo=FALSE, fig.height=6, fig.width=6, message=FALSE, warning=FALSE}
# missingness
plot_md_pat(pop)
# TODO: add pattern by cluster, text mining example square size
# TODO: try to make it a shepley plot 
```

- Does the missing data of `popular` depend on `popteach`? Does the missingness in teacher popularity depend on pupil popularity? -> Check this by making a histogram of `popteach` separately for the pupils with known popularity and missing popularity, and the other way around. 


```{r pop_dist, echo=FALSE, message=FALSE, warning=FALSE}
# distributions
# plot_NA_cond(pop, x = "popteach", z = "popular", bins = 1)
# plot_NA_cond(pop, x = "popular", z = "popteach", bins = 1)
# TODO: check if up-side-down plot works
# or maybe overlapping densities
# TODO: check smoothing in geom_density function and make it the inverse of the sample size
# TODO: add functions to mice

plot_col <- mice:::mdc(c("obs", "mis")) %>% setNames(c("observed", "missing"))

# x = "popular"
# z = "popteach"
plot_conditional <- function(data, x, z, cluster, ...){
  ggplot(data, aes(x = get(x), color = factor(is.na(get(z)), labels = c("missing", "observed")))) +
  geom_density(data = data %>% filter(!is.na(get(z))), aes(x = get(x), group = get(cluster)), alpha = 0.01, fill = plot_col[1], color = NA) +
  geom_density(data = data %>% filter(is.na(get(z))), aes(x = get(x), group = get(cluster)), alpha = 0.01, fill = plot_col[2], color = NA) +
  geom_density() +
  scale_color_manual(values = plot_col, name = z) +
  theme_classic() +
  theme(legend.position = "bottom") +
  labs(x = x)
}

plot_conditional(pop, x = "popular", z = "popteach", cluster = "class")
plot_conditional(pop, x = "popteach", z = "popular", cluster = "class")
# TODO: pooteach obs/mis
# TODO: add title
# TODO: add facets for some clusters
# or add propensity score distribution `is.na(popular) ~ .`
# TODO: make it average of cluster dens, not marginal
```

-  We do see that the distribution for the missing `popular` is further to the right than the distribution for observed `popular`. This would indicate a right-tailed MAR missingness. In fact this is exactly what happens, because we created the missingness in these data ourselves. But we made it observable by examining the relations between the missingness in popular and the observed data in `popteach`. There is also a dependency between the missingness in teacher popularity and pupil popularity. The relation seems to be right-tailed as well.

- We can impute the missingness the 'standard' way, ignoring the multilevel structure of the data. This is surely invalid, given the high ICCs, but we'll do it anyways.

- We'll use predictive mean matching to impute the continuous variables (some appear to be somewhat ordinal), and logistic regression to impute the binary variable `sex`. We do not use the observation identifier `pupil` or cluster identifier `class` as predictors to impute other variables.

```{r pop-ignored}
# dry run to get imputation parameters
ini <- mice(pop, maxit = 0)

# extract predictor matrix and adjust
pred <- ini$pred
pred[, c("class", "pupil")] <- 0
pred 

# impute the data, ignoring the cluster structure
imp_ignored <- mice(pop, maxit = 10, pred = pred, print = FALSE)

# check convergence of the imputation model
plot(imp_ignored)

# compare descriptives before and after imputation
psych::describe(pop)[, c("n", "mean", "median", "min", "max", "sd")]
psych::describe(mice::complete(imp_ignored))[, c("n", "mean", "median", "min", "max", "sd")] #note that this is just 1 imputation, not the pooled results
# TODO: add stripplot with boxplot overlay instead of the tables (make pooled one thick on top)
# TODO: pool mean median and sd
# feedback Stef: numbers, continuous statistics such as means, and uncertainty estimates. So we can pool the sd's. And leave out the min and max, because those are not normally distr.
# TODO: add FMI for each of the estimates? at least for the mean

# further inspection of the imputations
densityplot(imp_ignored)

# compare ICCs before and after imputation
ICCs <- data.frame(
  vars = c("popular", "popteach", "texp"), 
  incomplete = c(multilevel::ICC1(aov(popular ~ class, pop)), 
               multilevel::ICC1(aov(popteach ~ class, pop)),
               multilevel::ICC1(aov(texp ~ class, pop))), 
  ignored = c(multilevel::ICC1(aov(popular ~ class, complete(imp_ignored))), 
              multilevel::ICC1(aov(popteach ~ class, complete(imp_ignored))), 
              multilevel::ICC1(aov(texp ~ class, complete(imp_ignored))))
  )
ICCs


```

- As the original ICCs show, 100% of the variance in `texp` can be attributed to the clustering variable `class`. This tells us that the multilevel structure of the data should be taken into account. If we don't, we'll end up with incorrect imputations, biasing the effect of the clusters towards zero.

- We can also observe that the teacher experience increases slightly after imputation. This is due to the MNAR missingness in `texp`. Higher values for `texp` have a larger probability to be missing. This may not a problem, however, if at least one pupil in each class has teacher experience recorded, we can deductively impute the correct (i.e. true) value for every pupil in the class. 

- We'll now use `class` as a predictor to impute all other variables.

```{r pop-predictor}
# adjust the predictor matrix
pred <- ini$pred 
pred[, "pupil"] <- 0
pred

# impute the data, cluster as predictor
imp_predictor <- mice(pop, maxit = 10, pred = pred, print = FALSE)

# check logged events
head(imp_predictor$loggedEvents)
## "The mice() function detects multicollinearity, and solves the problem by removing one or more predictors for the model", in this case texp is removed as predictor of popular and popteach.

# check convergence of the imputation model
plot(imp_predictor)

# compare descriptives before and after imputation
psych::describe(pop)[, c("n", "mean", "median", "min", "max", "sd")]
psych::describe(mice::complete(imp_predictor))[, c("n", "mean", "median", "min", "max", "sd")] #note that this is just 1 imputation, not the pooled results

# further inspection of the imputations
densityplot(imp_predictor)

# compare ICCs before and after imputation
ICCs <- ICCs %>% cbind(
           predictor = c(multilevel::ICC1(aov(popular ~ class, complete(imp_predictor))), 
                        multilevel::ICC1(aov(popteach ~ class, complete(imp_predictor))), 
                        multilevel::ICC1(aov(texp ~ class, complete(imp_predictor))))
           )
ICCs
```

- Now, we can clearly see that the imputed values of `texp` are higher than the observed values, which is in line with right-tailed MNAR. 

- The ICCs are way more in line with the ICCs in the incomplete data. But this is a quick and dirty way of imputing multilevel data. We *should* be using a multilevel model.

## Amputation

- 


## Modeling choices

- Which models will we discuss? We'll build the model to grow in complexity. The final model is the most complex but also the most versatile. 

- Note on model complexity: Typically, we should at least use random intercepts, but often random slopes as well. Ideally we impute with random everything and heteroscedastic errors: most generic method (no worry about congeniality, but don't mention the term) ->  Refer to other papers for background, we'll focus just on the software implementation of the situations mentioned there. Sometimes there's little reason to assume some variable is affected by heterogeneity. -> Refer to @meng94, an Audigier paper, and a paper by Grund on congeniality and random slopes. 

- Step 0: As predictor + CCA to scare off users

- Step 1: Random intercepts

- Step 2: Random slopes

- Step 3: Residuals

- Heckman model for MNAR

- What do the different implementations look like? How to define the imputation model(s) in `mice`?

## Step 0

- AKA multilevel imputation for dummies. 

- Doesn't work for systematic missingness. 

## Step 1-3 + MNAR

- TODO: fill in.

## Pooling

- Analysis of scientific interest.

- Pooling using `mitml`.

- Pooling 'regular' parameters vs more 'exotic' parameters (SE of residual errors, or autocorrelation) 

- ADD: export `mids` objects to other packages like `lme4` or `coxme`? 


# Discussion

- JOMO in `mice` --> on the side for now

- Additional levels of clustering

- More complex data types: timeseries and polynomial relationship in the clustering.


# References

