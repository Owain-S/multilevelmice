---
documentclass: jss
author:
  - name: Hanne Oberman
    affiliation: Utrecht University
    address: |
      | Padualaan 14
      | 3584 CH Utrecht
    email: \email{h.i.oberman@uu.nl}
    url: https://hanneoberman.github.io/
  - name: Johanna Munoz Avila
    affiliation: University Medical Center Utrecht \AND
  - name: Valentijn de Jong
    affiliation: University Medical Center Utrecht 
  - name: Gerko Vink
    affiliation: Utrecht University \AND
  - name: Thomas Debray
    affiliation: University Medical Center Utrecht 
title:
  formatted: "Imputation of Incomplete Multilevel Data with \\pkg{mice}"
  plain:     "Imputation of Incomplete Multilevel Data with mice"
  short:     "Multilevel \\pkg{mice}"
abstract: >
  Multilevel data is not spared the ubiquitous problem of missing information. This is a tutorial paper on imputing incomplete multilevel data with \pkg{mice}. Including methods for ignorable and non-ignorable missingness. Footnotes in the current version show work in progress/under construction. The last section is not part of the manuscript, but purely for reminders.
keywords:
  # at least one keyword must be supplied
  formatted: [missing data, multilevel, clustering, "\\pkg{mice}", "\\proglang{R}"]
  plain:     [missing data, multilevel, clustering, mice, R]
preamble: >
  \usepackage{amsmath}
header-includes: 
 - \usepackage{graphicx} 
 - \usepackage{mathtools}
output: rticles::jss_article
bibliography: ../References/multilevelmice.bib
editor_options: 
  chunk_output_type: inline
---

```{r, setup, include=FALSE}
options(prompt = 'R> ', continue = '+ ')

# seed
set.seed(123)

# packages
library(tidyverse)
library(mice)
library(miceadds)
library(metamisc)
library(pan)

# functions
miceadds::source.all(path = "../R")
`%nin%` <- Negate(`%in%`)
icc <- function(formula, data){multilevel::ICC1(aov(formula, data))}

# plot parameters
plot_col <- mice:::mdc(1:2) %>% setNames(c("observed", "missing"))
```

# Introduction

## Multilevel data

Research into any field with a hierarchical or clustered nature of observations may yield multilevel data. In the typical case, individuals are nested within groups, but there are many different types of multilevel data. In the medical field, clustering occurs at e.g., the hospital or center level in registry data, or at the study-level in meta-analyses (IPDMA^[remove or write in full?]). In the social sciences and official statistics we can find clustering e.g. at the country-level, or as imposed by a multi-stage sampling design. For the sake of legibility, we will refer to the grouping variable as 'cluster', and the grouped variable as '(sample) unit' throughout this paper.^[Alternatives to unit: participant/response/record.] And, for reasons of brevity, we only discuss clustering between units, not within units (e.g., timeseries or longitudinal data).^[Also, add that we'll only discuss two levels, not more?] 

Analyzing multilevel data requires special care, compared to 'regular', single level data. For instance, there may be cross-level interactions between unit-level variables and cluster-level variables. The cluster to which a unit belongs may influence the unit-level observations, and vice versa for the the units that make up the cluster [@hox17]. These relations can and should be taken into account when developing analysis models for multilevel data.^[Explain ICC here? The percentage of variance attributed to the cluster-level is expressed by the intra-class coefficient (ICC). The ICC can also be interpreted as the expected correlation between two randomly sampled units in same cluster. So if the ICC is high, a lot of variability in a variable is due to the clustering, which should be modeled accordingly.] Multilevel models typically include separate intercepts for each cluster, which relieves one restriction imposed by single-level models: equal group means across clusters. Additionally, there may be random predictor effects and/or random error terms (residual error variances), see e.g. @hox17 and @jong21.^[Add that heterogeneity refers to variability within clusters.] There are many names for models that take clustering into account. Some popular examples are 'multilevel models', 'hierarchical models', 'mixed effect models' and 'random effect models'.

## Missing data

```{r patterns, fig.height=4, fig.width=3.2, fig.cap = "Missingness in multilevel data", echo=FALSE}
plot_md_set()
# TODO: add border/line
# TODO: remove unit
# TODO: add accolade

```

Multilevel data is not spared the ubiquitous problem of missing information. Just as in single level data, missingness may occur at the unit level. But with multiple levels of data comes the potential for missingness at multiple levels. Missingness in multilevel data can be categorized into two general patterns: systematical missingness and sporadic missingness, see @resc13. In figure 1, we show a dataset with units in the rows and variables in the columns, there are 5 units nested within 3 clusters, and 3 variables of interest. Variable `X1` is completely observed. Variable `X2` is systematically missing, `X3` is sporadically missing.^[Explain why.] Systematic missingness can be further subdivided into unobserved constants (i.e., the same value within clusters) and non-measured random variables (which may differ per unit within clusters). In Figure 1, the former implies that the unobserved values for units 3 and 4 on variable `X2` would be equal. With the latter, the values may differ. Depending on the missing data pattern^[add missing data mechanisms here?], there are more or less optimal way of accommodating the missingness. 

$$
\begin{matrix} 
                          &X1     & X2          & X3            \\
   \hline
   \mathrm{cluster 1}\{   &x_{11} &x_{12}       &\mathtt{NA}    \\
                          &x_{21} &x_{22}       &x_{32}         \\
   \mathrm{cluster 2}\{   &x_{31} &\mathtt{NA}  &x_{33}         \\
                          &x_{41} &\mathtt{NA}  &\mathtt{NA}    \\
   \mathrm{cluster 3}\{   &x_{51} &x_{52}       &x_{53}         \\
\end{matrix} 
$$

Ignoring missing data in research endeavors is almost never a good idea. Complete case analysis (i.e., excluding all units with one or more missing entries) can introduce bias in statistical inference and lowers statistical power. Instead, the missingness should be accommodated *before* or *within* the analysis of scientific interest. Especially the former is very generic and popular. Imputing (i.e., filling in) the missing values splits the missing data problem from the scientific problem. The \proglang{R} package \pkg{mice} has become the de-facto standard for imputation by chained equations, which solves the missingness one variable at a time, iteratively. \pkg{mice} is known to yield valid inferences under many different missing data circumstances [@buur18]. In this paper, we'll discuss how to use \pkg{mice} in the context of multilevel data, under varying missing data mechanisms.^[Discuss missingness mechanisms before this point, add references @yuce08 and @hox15.]


## Aim of this paper

This papers serves as a tutorial for imputing incomplete multilevel data with \pkg{mice}. We provide practical guidelines and code snippets for different missing data situations. For reasons of brevity, we focus on imputation by chained equations^[add that JOMO is available in \pkg{mice} as well?]. Other useful packages for incomplete multilevel data include \pkg{mitml}, \pkg{miceadds}, and \pkg{mdmb}.^[Rephrase: Some level of knowledge on multilevel models is assumed. We're providing an overview of implementations. It's up-to the reader to decide which multilevel strategy suits their data. So we won't go into detail for the different methods (and equations). Refer to @meng94, @audi18, and @grun18. This paper is just a software tutorial. We'll keep it practical.] 

We structure this tutorial around three case studies:

- `mice::popmis` (simulated data on school kids, with MNAR/MAR mixture);

- `metamisc::impact` (real IPD on traumatic brain injuries, without `NA`s);

- `GJRM::hiv` (simulated patient data on HIV, without `NA`s)

For each case study we focus on a different aspect to illustrate how to impute incomplete multilevel data. In the `mice::popmis` data, we show the advantages of including the multilevel structure of the data into the imputation model. In the `metamisc::impact` data we'll show how to induce missingness and solve it in real-world data. In the `GJRM::hiv` we provide novel methodology^[not really, the methods exist already, but how to show that this is something new and exciting?] for imputing MNAR missingness according to the Heckman model. For all case studies we discuss the nature of the incomplete data, the imputation model(s), and evaluation of the imputed data.

# Case Study I: Popularity

```{r pop, echo=FALSE, message=FALSE, warning=FALSE}
# load data 
pop <- readRDS("../Data/popNCR2.RDS") %>% mutate(class = as.factor(class))

# ICCs
icc_pop <- icc(popular ~ class, data = pop)
icc_teach <- icc(popteach ~ class, data = pop)
```

`popNCR` is a simulated dataset with pupils clustered in classes, where the number of units $n = 2000$, and the number of clusters $N = 100$, on 7 variables: 

  - `pupil`	Pupil number within class,
  - `class`	Class number,
  - `extrav`	Pupil extraversion,
  - `sex`	Pupil gender,
  - `texp`	Teacher experience (years),
  - `popular`	Pupil popularity,
  - `popteach`	Teacher popularity.
  
### Incomplete data

```{r pop_pat, echo=FALSE, fig.height=4, fig.width=4, fig.cap = "Missing data pattern in the popularity data", message=FALSE, warning=FALSE}
# missingness
plot_md_pat(pop)
# TODO: add pattern by cluster, text mining example square size
# TODO: try to make it a shepley plot 
```

The popularity data is created such that there are strong relations between the incomplete variables and the clustering variable `class`. We can express this using the intra-class correlation (ICC). For `popular` the ICC is `r round(icc_pop, 2)`. For `popteach` it is `r round(icc_teach, 2)`. It would thus be wise to use multilevel modeling.

The missingness in this dataset is induced conform MAR and MNAR mechanisms. The missing data pattern, Figure \ref{fig:pop_pat}, shows that just one variable is incomplete **[the next part is not yet updated to reflect this]**.

To develop the best imputation model, we need to know whether the missingness in one variable depends on the observed values of other variables. Visual inspection usually suffices. We'll highlight only two variables to illustrate, but ideally one would inspect all relations. The questions we'll ask are: 'Does the missing data of `popular` depend on `popteach`?' and 'Does the missingness in teacher popularity depend on pupil popularity?' We'll evaluate this by making a histogram of `popteach` separately for the pupils with known popularity and missing popularity, and the other way around.

In Figure \ref{fig:pop_dist} we see that the distribution for the missing `popular` is further to the right than the distribution for observed `popular`. This would indicate a right-tailed MAR missingness. In fact, this is exactly what happens, because the missingness in these data was created manually. Now, we've made it observable by examining the relations between the missingness in popular and the observed data in `popteach`. There is also a dependency between the missingness in teacher popularity and pupil popularity. The relation seems to be right-tailed as well.

```{r pop_dist, fig.cap = "Conditional distributions in the popularity data", echo=FALSE, message=FALSE, warning=FALSE}
plot_conditional(pop, x = "popteach", z = "popular", cluster = "class")
# TODO: check if up-side-down plot works
# TODO: check smoothing in geom_density function and make it the inverse of the sample size
# TODO: add functions to mice
# TODO: add title and informative legend
# TODO: add facets for some clusters
# or add propensity score distribution `is.na(popular) ~ .`
# TODO: make it average of cluster dens, not marginal
# alternatively add a quartile line around the density with geom_ribbon
```


### Imputation model  

The first imputation model that we'll use is likely to be invalid. In this model, we ignore the multilevel structure of the data, despite the high ICCs. This is purely to illustrate the effects of ignoring the clustering in our imputation effort.

We'll use predictive mean matching to impute the continuous variables and logistic regression to impute the binary variable `sex`. We do not use the observation identifier `pupil` or cluster identifier `class` as predictors to impute other variables.

```{r pop_ignored, echo=TRUE, message=FALSE, warning=FALSE}
# dry run to get imputation parameters
ini <- mice(pop, maxit = 0)

# extract predictor matrix and adjust
pred <- ini$pred
pred[, c("class", "pupil")] <- 0

# impute the data, ignoring the cluster structure
imp_ignored <- mice(pop, maxit = 1, pred = pred, print = FALSE)
```

### Imputed data

```{r pop_ignored_eval, echo=FALSE, message=FALSE, warning=FALSE}
# # check convergence of the imputation model
# plot(imp_ignored)

# # compare descriptives before and after imputation
# psych::describe(pop)[, c("n", "mean", "median", "min", "max", "sd")]
# psych::describe(mice::complete(imp_ignored))[, c("n", "mean", "median", "min", "max", "sd")] #note that this is just 1 imputation, not the pooled results
# TODO: add stripplot with boxplot overlay instead of the tables (make pooled one thick on top)
# TODO: pool mean median and sd
# feedback Stef: numbers, continuous statistics such as means, and uncertainty estimates. So we can pool the sd's. And leave out the min and max, because those are not normally distr.
# TODO: add FMI for each of the estimates? at least for the mean

# further inspection of the imputations
plot_box(imp_ignored, x = "popular", strip = TRUE)
# TODO: think about multimodality


# compare ICCs before and after imputation
ICCs <- data.frame(
  vars = c("popular", "popteach", "texp"), 
  incomplete = c(icc(popular ~ class, pop), 
               icc(popteach ~ class, pop),
               icc(texp ~ class, pop)), 
  ignored = c(icc(popular ~ class, complete(imp_ignored)), 
              icc(popteach ~ class, complete(imp_ignored)), 
              icc(texp ~ class, complete(imp_ignored)))
  )
ICCs
```

As the original ICCs show, 100% of the variance in `texp` can be attributed to the clustering variable `class`. This tells us that the multilevel structure of the data should be taken into account. If we don't, we'll end up with incorrect imputations, biasing the effect of the clusters towards zero.

We can also observe that the teacher experience increases slightly after imputation. This is due to the MNAR missingness in `texp`. Higher values for `texp` have a larger probability to be missing. This may not a problem, however, if at least one pupil in each class has teacher experience recorded, we can deductively impute the correct (i.e. true) value for every pupil in the class. 

### Imputation model

We'll now use `class` as a predictor to impute all other variables. This is still not recommended practice, since it only works under certain circumstances and results may be biased. But at least, it includes some multilevel aspect. Colloquially, this is 'multilevel imputation for dummies'. 

```{r pop_predictor, message=FALSE, warning=FALSE}
# adjust the predictor matrix
pred <- ini$pred 
pred[, "pupil"] <- 0

# impute the data, cluster as predictor
imp_predictor <- mice(pop, maxit = 1, pred = pred, print = FALSE)

```


### Imputed data

```{r pop_predictor_eval, echo=FALSE, message=FALSE, warning=FALSE}
# # check logged events
# head(imp_predictor$loggedEvents)
## "The mice() function detects multicollinearity, and solves the problem by removing one or more predictors for the model", in this case texp is removed as predictor of popular and popteach.

# # check convergence of the imputation model
# plot(imp_predictor)

# # compare descriptives before and after imputation
# psych::describe(pop)[, c("n", "mean", "median", "min", "max", "sd")]
# psych::describe(mice::complete(imp_predictor))[, c("n", "mean", "median", "min", "max", "sd")] #note that this is just 1 imputation, not the pooled results

# further inspection of the imputations
plot_box(imp_predictor, x = "popular", strip = TRUE)

# compare ICCs before and after imputation
ICCs <- ICCs %>% mutate(
           predictor = c(icc(popular ~ class, complete(imp_predictor)), 
                        icc(popteach ~ class, complete(imp_predictor)), 
                        icc(texp ~ class, complete(imp_predictor)))
           )
ICCs
```

Now, we can clearly see that the imputed values of `texp` are higher than the observed values, which is in line with right-tailed MNAR. 

The ICCs are way more in line with the ICCs in the incomplete data. But this is a quick and dirty way of imputing multilevel data. We *should* be using a multilevel model.


### Imputation model

To include...

```{r pop_norm}
pred <- ini$pred
pred["popular", ] <- c(0, -2, 2, 2, 2, 0, 2) 
#-2 for the cluster variable, 2 for random effects
meth <- ini$meth
meth <- c("", "", "", "", "", "2l.norm", "")
imp_norm_2l <-
  mice(
    pop %>% mutate(class = as.integer(class)),
    pred = pred,
    meth = meth,
    maxit = 1,
    print = FALSE
  )
```

```{r pop_norm_eval}
# plot(imp_norm)
plot_box(imp_norm_2l, x = "popular", strip = TRUE)

ICCs <- ICCs %>% mutate(
           norm = c(icc(popular ~ as.factor(class), complete(imp_norm_2l)), 
                    icc(popteach ~ as.factor(class), complete(imp_norm_2l)), 
                    icc(texp ~ as.factor(class), complete(imp_norm_2l)))
           )
ICCs
```

```{r pop_pan}
pred["popular", ] <- c(0, -2, 2, 2, 1, 0, 2)
meth <- c("", "", "", "", "", "2l.pan", "")
imp_pan_2l <-
  mice(
    pop %>% mutate(class = as.integer(class)),
    pred = pred,
    meth = meth,
    maxit = 1,
    print = FALSE
  )

```


```{r pop_pan_eval}
# plot(imp_pan)
plot_box(imp_pan_2l, x = "popular", strip = TRUE)
ICCs <- ICCs %>% mutate(
           pan = c(icc(popular ~ as.factor(class), complete(imp_pan_2l)), 
                    icc(popteach ~ as.factor(class), complete(imp_pan_2l)), 
                    icc(texp ~ as.factor(class), complete(imp_pan_2l)))
           )
ICCs
```

# Case study II: IMPACT

`impact` is traumatic brain injury data with patients, $n = 11022$, clustered in studies, $N = 15$. With the following 11 variables:

  - `name` Name of the study,
  - `type` Type of study (RCT: randomized controlled trial, OBS: observational cohort),
  - `age` Age of the patient,
  - `motor_score` Glasgow Coma Scale motor score,
  - `pupil` Pupillary reactivity,
  - `ct` Marshall Computerized Tomography classification,
  - `hypox` Hypoxia (0=no, 1=yes),
  - `hypots` Hypotension (0=no, 1=yes),
  - `tsah` Traumatic subarachnoid hemorrhage (0=no, 1=yes),
  - `edh` Epidural hematoma (0=no, 1=yes),
  - `mort` 6-month mortality (0=alive, 1=dead).

The data is already imputed (Steyerberg et al, 2008), so we'll induce missingness ourselves. For example, MAR missingness varying by cluster.^[Observed data pattern should differ per cluster. So, in cluster 1, the missingness would depend on age, but not in cluster two. Split the dataframe and run `ampute()` on each cluster.]

```{r impact, echo=FALSE}
# load data
data("impact")
# # descriptive statistics
# by(impact, impact$name, summary) 
# psych::describe(impact)[,c(2:5,8:9)]
# # missingness
# plot_md_pat(impact)
# TODO: rotate variable labels

# TODO: check md pattern in clusters, should differ, otherwise create new missingness
# MAYBE: think about nr of clusters: if there's too many, faceting is no option -> some distribution across the clusters instead
# TODO: e-mail Joop for DGM or look at adrew and jennifer book for data
# sim.multi from psych
```


# Case study III: HIV

Toy example from [Heckman Github repo](https://github.com/johamunoz/Heckman-IPDMA/blob/main/Toy_example.R).


# Discussion

- JOMO in \pkg{mice} -> on the side for now

- Additional levels of clustering

- More complex data types: timeseries and polynomial relationship in the clustering.


# Think about

- Adding some kind of help function to mice that suggests a suitable predictor matrix to the user, given a certain analysis model.

- Adding a `multilevel_ampute()` wrapper function in mice.

- Exporting `mids` objects to other packages like `lme4` or `coxme`? 

- Adding a ICC=0 dataset to show that even if there is no clustering it doesn't hurt.

# References

